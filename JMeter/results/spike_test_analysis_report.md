# Performance Analysis Report: Spike Test - Characters API

## 1. Overview
- **Test Type**: Spike Testing
- **Target Endpoint**: `https://thesimpsonsapi.com/api/characters`
- **Load Profile**:
  - **Baseline**: 0 users
  - **Spike**: 200 concurrent users
  - **Ramp-up**: 1 second
  - **Duration**: 120 seconds
- **Date of Execution**: 2026-01-26

---

## 2. Executive Summary
The spike test was conducted to evaluate the system's resilience to sudden traffic bursts. While the system maintained **100% availability** (no errors recorded), it failed to meet the Performance SLAs due to significant latency degradation under peak load.

| Metric | Target (SLA) | Actual Value | Status |
| :--- | :--- | :--- | :--- |
| **Error Rate** | < 1% | **0.0%** | ✅ PASS |
| **Avg Response Time** | < 1,000 ms | **591.02 ms** | ✅ PASS |
| **95th Percentile** | < 2,000 ms | **3,039.00 ms** | ❌ FAIL |
| **Throughput** | ≥ 100 req/s | **321.71 req/s** | ✅ PASS |
| **Max Response Time** | N/A | **22,294.00 ms** | ⚠️ CRITICAL |

---

## 3. Key Findings & Discoveries

*   **Resilience vs. Performance**: The API is stable and handles the load without crashing or dropping connections. However, "stability" here comes at the cost of extreme latency.
*   **Queuing Phenomenon**: A median response time of **51 ms** compared to a maximum of **22.3 seconds** indicates severe request enqueuing. Requests are waiting in the server buffer rather than being rejected.
*   **Latency Tail (Long Tail)**: The jump from the 90th percentile (1.2s) to the 99th percentile (7s) shows that while most requests are fast, a significant group of users experiences unacceptable wait times during the burst.
*   **Efficient Mini-Latency**: The minimum response time of **8 ms** suggests that some requests are likely served from a cache layer, but this layer is insufficient to mask the backlog during a 200-user spike.

---

## 4. Bottleneck Diagnosis

1.  **Resource Contention**: The massive spike in maximum latency (22s) strongly suggests that the **Thread Pool** or **Database Connection Pool** reached its limit, causing new requests to block until others finished.
2.  **Lack of Protective Measures**: The absence of a "Fail-Fast" mechanism or Circuit Breaker means the system attempts to process every request even when it's overloaded, degrading the experience for all users.
3.  **Scaling Lag**: If hosted on auto-scaling infrastructure, the spike duration (2 mins) was likely too short for new instances to spin up and assist with the load, but long enough to saturate existing nodes.

---

## 5. Action Plan

### Short-Term Recommendations
*   **Pool Tuning**: Increase the `max-threads` and `connection-pool-size` settings in the application server to handle a higher concurrency floor.
*   **Fail-Fast Mechanism**: Implement **Rate Limiting** (e.g., 200 req/s per node) at the Gateway level to return `429` status codes instead of allowing latency to climb to >20s.
*   **Cache Optimization**: Review the Cache-Control headers for `/api/characters`. Increasing the TTL for the first results page could significantly reduce backend hits during spikes.

### Medium-Term Recommendations
*   **Infrastructure Scaling**: Adjust scaling triggers to be more proactive (e.g., scale on *Request Rate* surge rather than *CPU* usage).
*   **Break-Point Analysis**: Conduct a Stress Test starting at 50 users and increasing slowly to identify the exact "knee" of the curve where latency exceeds 2 seconds.
*   **Optimization of /characters**: Profile the database query for the characters list. A 22s wait suggests that the query itself might be locking resources or lacks optimal indexing when many concurrent read requests occur.

---
**Report generated by Antigravity AI**
