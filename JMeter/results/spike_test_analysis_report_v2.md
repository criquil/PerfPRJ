# Performance Analysis Report: Advanced Spike Test (v2) - Characters API

## 1. Overview
- **Test Type**: Advanced Spike Testing (Normal -> Peak -> Normal)
- **Target Endpoint**: `https://thesimpsonsapi.com/api/characters`
- **Load Profile**:
  - **Cold Baseline**: 20 concurrent users (0s - 60s)
  - **Extreme Spike**: 200 concurrent users (60s - 120s) - *+180 users burst*
  - **Recovery Phase**: 20 concurrent users (120s - 180s)
- **Date of Execution**: 2026-01-26

---

## 2. Executive Summary
The test successfully simulated a sudden surge of traffic followed by a return to normal load. The system **failed to meet availability and recovery standards**. While it maintained throughput, the error rate spiked to **21%** and the server suffered from a persistent "recovery lag," impacting users even after the spike had ended.

| Metric | Phase: Spike Peak | Phase: Recovery | Target (SLA) | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Error Rate** | **21.56%** | **4.49%** | < 1% | ❌ FAIL |
| **Avg Response Time** | 524.67 ms | 189.82 ms | < 800 ms | ✅ PASS |
| **95th Percentile** | 1,450.95 ms | 629.20 ms | < 800 ms | ❌/✅ |
| **Max Response Time** | **22,141.00 ms** | **7,152.00 ms** | N/A | ⚠️ CRITICAL |
| **Throughput** | 310.54 req/s | 6.16 req/s | N/A | ✅ |

---

## 3. Key Findings & Discoveries

*   **Saturation Point**: The system's breaking point is clearly below 200 users. Upon hitting this threshold, the API immediately began rejecting 1 in 5 requests (21.5% errors).
*   **"Sticky" Latency (The Laggard Recovery)**: The most critical discovery is that the system **does not recover immediately**. Baseline users experienced latencies of up to **7.1 seconds** and an error rate of **4.5%** for several minutes after the 180 extra users were removed.
*   **Queuing and Resource Exhaustion**: The maximum response time of **22 seconds** during the spike confirms that the server's thread pool was completely saturated, causing a backlog that "leaked" into the recovery phase.
*   **Cache Ineffectiveness under Stress**: Although the median RT remained relatively low (180ms), the high variance in the 99th percentile (3.3s) shows that caching cannot mitigate the architectural bottleneck when concurrency is high.

---

## 4. Bottleneck Diagnosis

1.  **Thread Pool Starvation**: The server is likely configured with a limited number of worker threads. When the spike hits, these threads are blocked by slow I/O or database locks, preventing even the "normal" baseline traffic from being processed.
2.  **Database Connection Lead-out**: The slow recovery (7s latencies after the spike) strongly suggests that the database connection pool remained saturated with "ghost" queries or orphan connections from the spike phase.
3.  **Lack of Health Checks/Circuit Breaking**: The system continues to attempt processing even when it is clearly failing, which prevents it from purging the request queue quickly once the load drops.

---

## 5. Action Plan

### Short-Term Recommendations (Immediate)
*   **Implement Aggressive Timeouts**: Reduce the server-side request timeout to 5 seconds. This will force the system to drop "doomed" requests faster and free up threads for new baseline traffic.
*   **Tuning the Connection Pool**: Increase the `max-connections` for the database and reduce the `idle-timeout` to ensure connections are recycled faster after a surge.
*   **Gateway Rate Limiting**: Limit the API to 250 requests per second. It is better to return a controlled `429` error than to allow the system to reach 22-second response times.

### Medium-Term Recommendations
*   **Asynchronous Processing**: Evaluate if parts of the `/characters` request can be handled asynchronously or served from a more robust read-replica strategy.
*   **Self-Healing Infrastructure**: Configure auto-scaling to trigger on **Latency Thresholds** (e.g., if P95 > 1s, start a new instance immediately) rather than just CPU usage.
*   **Recovery Validation**: Perform a "Step Recovery Test" (decreasing load from 200 to 150, then 100, then 50) to find the threshold where the system recovers instantly.

---
**Report generated by Antigravity AI**
